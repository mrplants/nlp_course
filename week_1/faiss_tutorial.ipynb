{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> DUPLICATE THIS COLAB TO START WORKING ON IT. Using File > Save a copy to drive.\n",
    "\n",
    "\n",
    "# Week 3: FAISS Tutorial\n",
    "\n",
    "### What we are looking at\n",
    "The goal of this small tutorial, is to provide you a quick overview into what FAISS does and how you can utilize it for Week 3 project. FAISS is an index for efficiently storing searchable embeddings of objects (e.g. sentences, images, ...). This efficient storing allows us to quickly compare our current object against the objects present in the index, and thus find relevant similar results. FAISS uses approximate nearest neighbor search to achieve these quick results.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Go through all the steps and look at what kind of embeddings we create.\n",
    "1. Feel free to add more sentences to be embedded.\n",
    "1. Make sure to have a look at the interactive graph, and see how close some results are, and how some are not. Does it make sense?\n",
    "1. Have a look at the results retrieved from the FAISS index we made. Are they appropriate? Try and play around with the number of results it retrieves.\n",
    "\n",
    "### Code Overview\n",
    "\n",
    "- Dependencies: Install and import python dependencies\n",
    "- Dataset creation\n",
    "- Cohere API\n",
    "- Creating a FAISS index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "âœ¨ Now let's get started! To kick things off, as always, we will install some dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation\n",
    "\n",
    "Below we create our own small dataset, and its WONDERFULðŸ¤©. Please feel free to add your own examples to it, the more the betterâœ¨âœ¨! We make use of Spacy to quickly retrieve sentence embeddings that can be used for storing in our FAISS index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "             # Movies\n",
    "             \"I am watching a movie.\",\n",
    "             \"I'm going to the movies.\",\n",
    "             \"Cinema's popcorn smell is amazing.\",\n",
    "             \"These guys kept talking while I was watching the movie.\",\n",
    "             # Groceries\n",
    "             \"Groceries are expensive now?\",\n",
    "             \"What happend to all my groceries, they are all rotten.\",\n",
    "             \"I like avocado toast\",\n",
    "             \"Cheese is over there!\",\n",
    "             \"Spinach is the food of the gods.\",\n",
    "             \"Healthy dose of protein powder is always good.\",\n",
    "             # Music\n",
    "             \"Coldplay is not my favorite band anymore.\",\n",
    "             \"I really liked MTV, with all the video clips.\",\n",
    "             \"What music would you like me to play?\",\n",
    "             \"He's playing piano very well.\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "vectors = np.array([nlp(sentence).vector for sentence in sentences])\n",
    "vectors.shape\n",
    "\n",
    "# NOTE:  We are using Spacy here because it is free.  If you like, you can use one of the following\n",
    "#        commercial offerings:\n",
    "#        - OpenAI\n",
    "#        = Cohere\n",
    "\n",
    "# Here is an example of how to get the same sentence embeddings using the OpenAI API\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "\n",
    "# response = client.embeddings.create(\n",
    "#     input=sentences,\n",
    "#     model=\"text-embedding-3-small\"\n",
    "# )\n",
    "\n",
    "# vectors = np.array([data.embedding for data in response.data])\n",
    "# vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we make use of UMAP and altair. UMAP we use to reduce the dimensions of our embeddings. With Altair we make an interactive plot.\n",
    "\n",
    "Please hover over some of these points and see if you can identify a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grinch/Developer/nlp_course/nlp_course_env/lib/python3.11/site-packages/umap/umap_.py:2433: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ead8ed37f8424f438fdaf112ec63b65c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ead8ed37f8424f438fdaf112ec63b65c.vega-embed details,\n",
       "  #altair-viz-ead8ed37f8424f438fdaf112ec63b65c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ead8ed37f8424f438fdaf112ec63b65c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ead8ed37f8424f438fdaf112ec63b65c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ead8ed37f8424f438fdaf112ec63b65c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-33ff24b4f92053275fb631d6ca5a84bf\"}, \"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"tooltip\": [{\"field\": \"text\", \"type\": \"nominal\"}], \"x\": {\"field\": \"x\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}, \"height\": 400, \"params\": [{\"name\": \"param_2\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"width\": 700, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-33ff24b4f92053275fb631d6ca5a84bf\": [{\"text\": \"I am watching a movie.\", \"x\": 14.665898323059082, \"y\": -3.1030666828155518}, {\"text\": \"I'm going to the movies.\", \"x\": 14.7404146194458, \"y\": -2.5450305938720703}, {\"text\": \"Cinema's popcorn smell is amazing.\", \"x\": 12.746898651123047, \"y\": -2.002072334289551}, {\"text\": \"These guys kept talking while I was watching the movie.\", \"x\": 15.101405143737793, \"y\": -1.5663645267486572}, {\"text\": \"Groceries are expensive now?\", \"x\": 13.690478324890137, \"y\": -0.9616332650184631}, {\"text\": \"What happend to all my groceries, they are all rotten.\", \"x\": 14.297224998474121, \"y\": -1.8426622152328491}, {\"text\": \"I like avocado toast\", \"x\": 15.386659622192383, \"y\": -2.866384983062744}, {\"text\": \"Cheese is over there!\", \"x\": 12.936169624328613, \"y\": -1.216672658920288}, {\"text\": \"Spinach is the food of the gods.\", \"x\": 12.337583541870117, \"y\": -0.9735413789749146}, {\"text\": \"Healthy dose of protein powder is always good.\", \"x\": 12.114925384521484, \"y\": -1.7126520872116089}, {\"text\": \"Coldplay is not my favorite band anymore.\", \"x\": 13.487933158874512, \"y\": -1.823606252670288}, {\"text\": \"I really liked MTV, with all the video clips.\", \"x\": 15.562712669372559, \"y\": -2.0963995456695557}, {\"text\": \"What music would you like me to play?\", \"x\": 14.103583335876465, \"y\": -2.6280500888824463}, {\"text\": \"He's playing piano very well.\", \"x\": 14.578083992004395, \"y\": -1.1212695837020874}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UMAP reduces dimensions from 300 to 2, which we can plot\n",
    "reducer = umap.UMAP()\n",
    "umap_embeds = reducer.fit_transform(vectors)\n",
    "# Make interactive plot\n",
    "df_explore = pd.DataFrame(data={'text': df['conversation']})\n",
    "df_explore['x'] = umap_embeds[:,0]\n",
    "df_explore['y'] = umap_embeds[:,1]\n",
    "chart = alt.Chart(df_explore).mark_circle(size=60).encode(\n",
    "    x=alt.X('x', scale=alt.Scale(zero=False)),\n",
    "    y=alt.Y('y', scale=alt.Scale(zero=False)),\n",
    "    tooltip=['text']\n",
    ").properties(width=700, height=400)\n",
    "chart.interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating FAISS: the good stuff.\n",
    "Creating FAISS is rather straightforward.\n",
    "1. Identify which index you want to use, with the dimension your embeddings have.\n",
    "1. Add all the embeddings you want to add.\n",
    "\n",
    "Since we made embeddings of sentences, we can now query this index with an example like *\"I like eating cabbage\"*. We turn this into a embedding and search for related sentences in our small index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like avocado toast | score: 1439.9027099609375\n",
      "I am watching a movie. | score: 1260.8111572265625\n",
      "I'm going to the movies. | score: 1248.7900390625\n",
      "What music would you like me to play? | score: 1124.860595703125\n",
      "What happend to all my groceries, they are all rotten. | score: 940.5963134765625\n"
     ]
    }
   ],
   "source": [
    "# Create our Approximate Nearest Neighbour Index (ANN)\n",
    "# https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index\n",
    "faiss_index = faiss.IndexFlatIP(vectors.shape[1])\n",
    "\n",
    "# Convert from float64 to float32 to prevent bug:\n",
    "# https://github.com/facebookresearch/faiss/issues/461\n",
    "faiss_index.add(vectors)\n",
    "\n",
    "# Create an embedding for our sentence\n",
    "vector = np.array(nlp('I like eating cabbage!').vector).reshape(1, -1)\n",
    "\n",
    "# Get the results\n",
    "scores, indices = faiss_index.search(vector, 5)\n",
    "\n",
    "# Print the results\n",
    "for index, score in zip(indices[0], scores[0]):\n",
    "    print(f'{sentences[index]} | score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ¨ Tada âœ¨, hopefully the results match your expectations!\n",
    "\n",
    "ðŸ™Œ Good luck with the project! ðŸ™Œ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
